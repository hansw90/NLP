{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코사인 유사도 (Cosine Similarity)\n",
    "\n",
    "BoW 나 Bow에 기반한 단어 표현 방법인 DTM, TF-IDF, 워드투벡터 등과 같이 단어를 수치화활 수 있는 방법을 이해했다면, 이러한 표현 방법에 대해서 코사인 유사도를 이용하여 문서의 유사도를 구하는게 가능하다.  \n",
    "\n",
    "## 1. 코사인 유사도 (Cosine Similarity)\n",
    "\n",
    "코사인 유사도는 두 벡터 간의 코사인 각도를 이용하여 구할 수 있는 두 벡터의 유사도를 의미합니다. 두 벡터의 방향이 완전히 동일한 경우에는 1의 값을 가지며, 90도의 각을 이루면 0,180도로 반대의 방향을 가지면 -1의 값을 갖게 됩니다. 즉, 결국 코사인 유사도는 -1 이상 1 이하의 값을 가지며 값이 1에 가까울수록 유사도가 높다고 판단 할 수 있습니다. 이를 직관적으로 이해하면 두 벡터가 가리키는 방향이 얼마나 유사한가를 의미합니다.\n",
    "\n",
    "![](https://wikidocs.net/images/page/24603/%EC%BD%94%EC%82%AC%EC%9D%B8%EC%9C%A0%EC%82%AC%EB%8F%84.PNG)\n",
    "\n",
    "두 벡터 A, B에 대해서 코사인 유사도는 식으로 표현하면 다음과 같다.\n",
    "\n",
    "![](datasets/img/20191016_223535.png)\n",
    "\n",
    "문서 단어 행렬이나 TF-IDF 행렬을 통해서 문서의 유사도를 구하는 경우에는 문서 단어 행렬이나 TF-IDF행렬이 각각의 특징 벡터 A, B가 됩니다. 그렇다면 문서 단어 행렬에 대해서 코사인 유사도를 구해보는 간단한 예제를 진행해보겠습니다.  \n",
    "\n",
    "문서1 : 저는 사과 좋아요  \n",
    "문서2 : 저는 바나나 좋아요  \n",
    "문서3 : 저는 바나나 좋아요 저는 바나나 좋아요  \n",
    "\n",
    "위의 세 문섯에 대해서 문서 단어 행렬을 만들면 이와 같습니다.  \n",
    "![](datasets/img/20191016_223752.png)\n",
    "\n",
    "파이썬에서는 코사인 유사도를 구하는 방법은 여러가지가 있는데 여기서는 Numpy를 이용해서 계산해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import math\n",
    "def cos_sim(A,B) :\n",
    "    return dot(A,B)/(norm(A) * norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코사인 유사도를 계산하는 함수를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=np.array([0,1,1,1])\n",
    "doc2=np.array([1,0,1,1])\n",
    "doc3=np.array([2,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(doc1, doc2)) #문서1과 문서2의 코사인 유사도\n",
    "print(cos_sim(doc1, doc3)) #문서1과 문서3의 코사인 유사도\n",
    "print(cos_sim(doc2, doc3)) #문서2과 문서3의 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "a=np.array([2,2,2,2]) # sqrt(2**2 + 2**2 + 2**2 + 2**2)\n",
    "print(norm(a))\n",
    "b= math.sqrt(2**2 + 2**2 + 2**2 + 2**2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "눈여겨볼만한 점은 문서1과 문서2의 코사인 유사도와 문서1과 문서3의 코사인 유사도가 같다는 점과 문서2와 문서3의 코사인 유사도가 1이 나온다는 것입니다. 앞서 1은 두 벡터의 방향이 완전히 동일한 경우에 1이 나오며, 코사인 유사도 관점에서는 유사도의 값이 최대임을 의미합니다.  \n",
    "\n",
    "문서3은 문서2에서 단지 모든 단어의 빈도수가 1씩 증가했을 뿐입니다. 이는 한 문서 내의 모든 단어의 빈도수가 똑같이 증가하는 경우에는 기존의 문서와 코사인 유사도의 값이 1이라는 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
