{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 워드 임베딩과 Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어의 속성과 형태는 사람이 처리하기에는 쉬운 형태로 발전해 왔지만, 컴퓨터가 이해하고 처리하기에는 굉장히 어려운 형태로 발전해 왔다.   \n",
    "\n",
    "그렇기 때문에 앞으로 NLP를 하기위해선, 사람이 사용하는 자연어의 형태를 컴퓨터가 이해하는 벡터로 변환이 가능한 함수 또는 맵핑 테이블을 만들어 내는 과정은 매우 중요하다.  \n",
    "\n",
    "이번 장에선 시초인 원핫벡터부터, W2V, 그리고 현재 워드 임베딩까지 알아보도록 하겠다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi my name is han seung woo\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "word_list = input().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'my', 'name', 'is', 'han', 'seung', 'woo']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "for voca in word_list :\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 0, 'my': 1, 'name': 2, 'is': 3, 'han': 4, 'seung': 5, 'woo': 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "    one_hot_vector = [0]*(len(word2index))\n",
    "    index=word2index[word]\n",
    "    one_hot_vector[index]=1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for voca in word_list :\n",
    "    print(one_hot_encoding(voca, word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 경우도 0 이 너무 많은 sparse vector이다, 더욱이 문장이 더 길어진다면 그 차원의 수는 더 늘어날 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list2 = \"hi kkk how are you? what your name? ah my full name is seung woo han\".split()\n",
    "word2index = {}\n",
    "for voca in word_list2 :\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for voca in word_list :\n",
    "    print(one_hot_encoding(voca, word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터의 내적 \n",
    "np.dot(one_hot_encoding(word_list[0], word2index), one_hot_encoding(word_list[1], word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터의 내적이 0이라는건 선형독립, 즉 각 단어의 유사도를 측정이 불가능하다는 것이다,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 문제를 해결코자 2013년 구글에서 word2vec라는 임베딩 기법을 발표하였다, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워드투벡은 비지도학습 신경망을 이용한 워드 임베딩 기법이다.  \n",
    "학습 방법으론 CBOW와 Skip-gram 두가지가 제시된다.\n",
    "\n",
    "![](https://www.researchgate.net/profile/Daniel_Braun6/publication/326588219/figure/fig1/AS:652185784295425@1532504616288/Continuous-Bag-of-words-CBOW-CB-and-Skip-gram-SG-training-model-illustrations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "corpus = ['king is a strong man',\n",
    "    'queen is a wise woman',\n",
    "    'girl is a young woman',\n",
    "    'prince is a old king',\n",
    "    'prince is a king sun',\n",
    "    'woman going to be a queen',\n",
    "    'woman is pretty',\n",
    "    'man is  strong',\n",
    "    'prince is  old and he will be king',\n",
    "    'prince is a girl will be queen'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop word 를 제거한다. \n",
    "# 불용어 처리, 워드 전처리 에 대해선 나중에 더 다루어 보도록 하자,\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be',\"and\"]\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'girl',\n",
       " 'going',\n",
       " 'he',\n",
       " 'king',\n",
       " 'man',\n",
       " 'old',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'sun',\n",
       " 'to',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input   label\n",
       "0    king  strong\n",
       "1    king     man\n",
       "2  strong    king\n",
       "3  strong     man\n",
       "4     man    king\n",
       "5     man  strong\n",
       "6   queen    wise\n",
       "7   queen   woman\n",
       "8    wise   queen\n",
       "9    wise   woman"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 2.0버전에선 placeholder를 이용 안하기 때문에\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "##\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  5.402496\n",
      "iteration 3000 loss is :  1.9145833\n",
      "iteration 6000 loss is :  1.8042276\n",
      "iteration 9000 loss is :  1.75423\n",
      "iteration 12000 loss is :  1.7210377\n",
      "iteration 15000 loss is :  1.7076164\n",
      "iteration 18000 loss is :  1.698658\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.8032568  -1.0373008 ]\n",
      " [-3.4302993  -5.0473833 ]\n",
      " [ 0.32196677 -0.6637554 ]\n",
      " [-5.664946   -0.82820046]\n",
      " [-3.805704    2.9328356 ]\n",
      " [-0.6625798   0.3285321 ]\n",
      " [-3.1487238  -3.1620092 ]\n",
      " [-0.93280697 -0.09347403]\n",
      " [ 0.28495514 -4.840319  ]\n",
      " [-3.8820896  -0.3906256 ]\n",
      " [-0.03319585 -0.6428555 ]\n",
      " [-2.0293517   2.2571306 ]\n",
      " [-1.1243191  -5.066931  ]\n",
      " [-1.5290265  -1.444211  ]\n",
      " [-4.876838   -0.70383215]\n",
      " [ 0.27708066 -4.8028617 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-2.803257</td>\n",
       "      <td>-1.037301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pretty</td>\n",
       "      <td>-3.430299</td>\n",
       "      <td>-5.047383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.321967</td>\n",
       "      <td>-0.663755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sun</td>\n",
       "      <td>-5.664946</td>\n",
       "      <td>-0.828200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>strong</td>\n",
       "      <td>-3.805704</td>\n",
       "      <td>2.932836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>king</td>\n",
       "      <td>-0.662580</td>\n",
       "      <td>0.328532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>young</td>\n",
       "      <td>-3.148724</td>\n",
       "      <td>-3.162009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>prince</td>\n",
       "      <td>-0.932807</td>\n",
       "      <td>-0.093474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>going</td>\n",
       "      <td>0.284955</td>\n",
       "      <td>-4.840319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>he</td>\n",
       "      <td>-3.882090</td>\n",
       "      <td>-0.390626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>queen</td>\n",
       "      <td>-0.033196</td>\n",
       "      <td>-0.642856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>man</td>\n",
       "      <td>-2.029352</td>\n",
       "      <td>2.257131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>wise</td>\n",
       "      <td>-1.124319</td>\n",
       "      <td>-5.066931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>girl</td>\n",
       "      <td>-1.529027</td>\n",
       "      <td>-1.444211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>old</td>\n",
       "      <td>-4.876838</td>\n",
       "      <td>-0.703832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>to</td>\n",
       "      <td>0.277081</td>\n",
       "      <td>-4.802862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word        x1        x2\n",
       "0          -2.803257 -1.037301\n",
       "1   pretty -3.430299 -5.047383\n",
       "2    woman  0.321967 -0.663755\n",
       "3      sun -5.664946 -0.828200\n",
       "4   strong -3.805704  2.932836\n",
       "5     king -0.662580  0.328532\n",
       "6    young -3.148724 -3.162009\n",
       "7   prince -0.932807 -0.093474\n",
       "8    going  0.284955 -4.840319\n",
       "9       he -3.882090 -0.390626\n",
       "10   queen -0.033196 -0.642856\n",
       "11     man -2.029352  2.257131\n",
       "12    wise -1.124319 -5.066931\n",
       "13    girl -1.529027 -1.444211\n",
       "14     old -4.876838 -0.703832\n",
       "15      to  0.277081 -4.802862"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
