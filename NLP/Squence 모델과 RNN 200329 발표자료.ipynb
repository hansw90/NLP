{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Modeling 과 Recurrent Nueral Network\n",
    "\n",
    "### 한승우 200329 발표자료"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과거로 부터 미래를 예측하는 것이 가능할까??\n",
    "\n",
    "### 두가지 유형\n",
    "\n",
    "1. Sequence Prediction \n",
    "- 예시\n",
    "    - 사용자가 방문한 정보를 바탕으로 다음 방문할 웹페이지 예측 (혹은 구매 예측)\n",
    "    - DNA의 나선형 단백질 순서 모델링\n",
    "    - __자연어처리__\n",
    "    \n",
    "2. Time-Series Forcasting\n",
    "- 예시\n",
    "    - 지금까지의 주가 변동곡선을 바탕으로 다음 주가 변동 예측\n",
    "    - 특정 지역의 기후 데이터를 바탕으로 내일의 온도 변화 예측\n",
    "    - 공장 센서 데이터 변화 이력을 토대로 이상 발생 예측\n",
    " \n",
    " \n",
    "![](img/20200329_174444.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 ML은 X와 Y과계를 규명하는 모델 f를 통해 Y를 예측하는데 반해,  Time-Series 계열은 시간에 따른 Y 값의 변화에만 초점을 맞춘다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "rnn 을 들어가기 전에 우리는 state에 대해 먼저 알아야 한다. \n",
    "state 는 무엇일까?, 사전적 의미로는 아래와 같다.\n",
    "![state](img/20200329_175006.png)\n",
    "\n",
    "상태, 경계와 같은 의미로 쓰인다. 실제로 rnn에서도 이러한 개념으로 사용된다. \n",
    "\n",
    "### State in Sequence\n",
    "\n",
    "\n",
    "__Stateful vs Stateless ??__\n",
    "\n",
    "![](img/20200329_175213.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존의 DNN , feed foward model 은 이러한 sequence 데이터를 처리 하지 못할까?? \n",
    "\n",
    "- 연결위주 모델인 Deep Neural Network 는 Input 을 (Hidden) Feature Space 로 매핑하여,  그 space 상에서 경계선을 찾는 방식을 (통계적으로) 구현한다.\n",
    "\n",
    "- 귀납적 통계추론의 대원칙 : 그러나 Backpropagation을 통한 Hidden space 매핑이 바르게 이러어 지려면 반드시 입력데이터 (개사진, 고양이 사진.. ) 들끼리는 서로 __!!!독립!!!__ 이여야하 한다.!!\n",
    "\n",
    "![](img/20200329_175842.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대충 RNN 이 왜 필요한지 알았으면 RNN의 구조부터 살펴보며 알아보도록 하자 \n",
    "\n",
    "![](http://i.imgur.com/Q8zv6TQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 은 히든 노드가 방향을 가진 엣지로, (기존 Feed foward 신경망을 생각해보면, y(out-put)값 으로만 방향을 가진다) 연결돼 순환 구조를 이루는 (directed cycle)인공 신경망의 한 종류이다.  \n",
    "\n",
    "음성, 문자, 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있음  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림에서 알수 있듯 시퀀스 길이에 관계없이 인풋과 아웃풋을 받아 들일수 있는 네트워크 구조이며 그떄문에 다양하고 유연하게 구조를 만들 수 있다는 장점을 가지고 있음,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 의 기본구조 \n",
    "![](http://i.imgur.com/s8nYcww.png)\n",
    "\n",
    "위의 그림에서 \n",
    "- 녹색박스는 state 를 의미 \n",
    "- 빨간박스는 인풋 x 를 의미\n",
    "- 파란박스는 아웃풋 y 를 의미 \n",
    "\n",
    "현재 상태의 hidden state h_{t}는 직전 시점의 hidden state h_{t-1}를 받아 갱신이 된다.  \n",
    "\n",
    "위의 그림에서 h_{t} 가 어떻게 만들어 지는지 보면 알 수 있다.  \n",
    "\n",
    "------------------------------\n",
    "__Quiz))__\n",
    "x, state 는 vector이다. x는 one-hot vector도 가능하고 word2vec도 가능  \n",
    "그렇다면 RNN이 학습하는 W_{hh}, W_{xh} 등 파라미터 가중치들의 타입은 무엇일까??\n",
    "\n",
    "---------------------\n",
    "\n",
    "퀴즈에서 말한 parabeter들은 모든 시점의 state에서 이 parameter를 동일하게 적용합니다. 이것을 (shared weights)라고 합니다.  \n",
    "\n",
    "![](https://static.packt-cdn.com/products/9781787121089/graphics/image_06_008.png)\n",
    "여기서 알아야 될건 그 층에서의 weight를 공유 한다는 것이지 \n",
    "deep 한 모델의 경우 각각의 weight들을 공유 합니다 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN의 순전파 모습\n",
    "\n",
    "![](http://i.imgur.com/TIdBDTJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 의 역전파\n",
    "\n",
    "RNN 의 역전파는 수식적으로도 복잡하고 하여 따로 아래 링크를 통해 따로 정리하였습니다.\n",
    "\n",
    "RNN 의 역전파과정을 통해 RNN이 어떻게 학습이 되고, 이 학습과정에서 생기는 문제점이 무엇인지 알아보도록 하겠습니다 .\n",
    "\n",
    "https://github.com/hansw90/NLP/blob/master/NLP/RNN%20%EC%9D%98%20LOSS%20%EC%99%80%20BPTT%20(Backprop%20Through%20Time)%20%EC%97%90%20%EB%8C%80%ED%95%B4%20%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
